{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Loan Prediction Machine Learning Model\n",
    "\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, recall_score, roc_curve, auc, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df = pd.read_csv('../data/vehicle_loans_feat.csv', index_col='UNIQUEID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like we did for Logistic Regression let's convert our categorical variables to the 'category' data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_cols = ['MANUFACTURER_ID', 'STATE_ID', 'DISBURSAL_MONTH', 'DISBURSED_CAT', 'PERFORM_CNS_SCORE_DESCRIPTION', 'EMPLOYMENT_TYPE']\n",
    "loan_df[category_cols] = loan_df[category_cols].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring the plot_roc_curve and eval_model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, roc_auc):\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, x_test, y_test):\n",
    "    preds = model.predict(x_test)\n",
    "    probs = model.predict_proba(x_test)\n",
    "\n",
    "    conf_mat = confusion_matrix(y_test, preds)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "    precision = precision_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "\n",
    "    plot_confusion_matrix(model, x_test, y_test)\n",
    "    plt.show()\n",
    "\n",
    "    #print(conf_mat)\n",
    "    print(\"\\n\")\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1: \", f1)\n",
    "\n",
    "    #Show ROC Curve \n",
    "    fpr, tpr, threshold = roc_curve(y_test, probs[:,1], pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(\"AUC: \", roc_auc)\n",
    "\n",
    "    plot_roc_curve(fpr, tpr, roc_auc)\n",
    "\n",
    "    results_df = pd.DataFrame()\n",
    "    results_df['true_class'] = y_test\n",
    "    results_df['predicted_class'] = list(preds)\n",
    "    results_df['default_prob'] = probs[:, 1]\n",
    "\n",
    "    #plot the distribution of probabilities for the estimated classes \n",
    "    sns.distplot(results_df[results_df['true_class'] == 0]['default_prob'], label=\"No Default\", hist=False)\n",
    "    sns.distplot(results_df[results_df['true_class'] == 1]['default_prob'], label=\"Default\", hist=False)\n",
    "    plt.title('Distribution of Probabilities for Estimated Classes')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    #see the true class versus predicted class as a percentage\n",
    "    print(results_df.groupby('true_class')['predicted_class'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Building The Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_split(loan_df):\n",
    "    loan_data_dumm = pd.get_dummies(loan_df, prefix_sep='_', drop_first=True)\n",
    "\n",
    "    x = loan_data_dumm.drop(['LOAN_DEFAULT'], axis=1)\n",
    "    y = loan_data_dumm['LOAN_DEFAULT']\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test our new function and create a training and test set for RandomForest, this time using the full set of features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = encode_and_split(loan_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape (186523, 92)\n",
      "Training Label Rows 186523\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Features Shape\", x_train.shape)\n",
    "print(\"Training Label Rows\", y_train.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Features Shape (46631, 92)\n",
      "Testing Label Rows 46631\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Features Shape\", x_test.shape)\n",
    "print(\"Testing Label Rows\", y_test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.783099\n",
      "1    0.216901\n",
      "Name: LOAN_DEFAULT, dtype: float64\n",
      "0    0.782248\n",
      "1    0.217752\n",
      "Name: LOAN_DEFAULT, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, x_test, y_test):\n",
    "    # Your evaluation code here\n",
    "    rfc_model = RandomForestClassifier()\n",
    "    rfc_model.fit(x_train, y_train)\n",
    "    eval_model(rfc_model, x_test, y_test)\n",
    "    # Generate the confusion matrix\n",
    "    confusion = confusion_matrix(y_test, preds)\n",
    "    \n",
    "    # Plot the confusion matrix\n",
    "    plot_confusion_matrix(model, x_test, y_test)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a minute to interpret these results \n",
    "\n",
    "### Accuracy \n",
    "\n",
    "- ~78% similar to the simple logistic regression model we built already\n",
    "\n",
    "### Precision \n",
    "\n",
    "- 39% better than simple logistic Regression which had ~33% \n",
    "- More of the instances we classified as defaults actually were defaults \n",
    "- However, most of the instances we classify as defaults are actually not defaults\n",
    "\n",
    "### Recall \n",
    "\n",
    "- Recall has increased dramatically, from 0.03% to 4.5%!\n",
    "- Random Forest picked up a lot more of the actual positive cases\n",
    "- It still missed most of them\n",
    "\n",
    "### F1\n",
    "\n",
    "- The F1 score has also increased dramatically from 0.0006 to ~0.08! \n",
    "- There is a better balance between Precision and Recall for Random Forest\n",
    "- Although this is still generally poor\n",
    "\n",
    "### AUC \n",
    "\n",
    "- The area under the roc curve has increased very slightly\n",
    "\n",
    "### Probability Distributions \n",
    "\n",
    "- Plot shows bad class separation \n",
    "- Majority of cases unlikely to be classified as defaults \n",
    "\n",
    "Generally the random forest is better than Logistic Regression but it is still not doing a good job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(rfc_model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our random forest is overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Trees \n",
    "\n",
    "Let's do some manual exploration of the forest size parameter, remember the default value is 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = RandomForestClassifier(n_estimators=1)\n",
    "rfc_model.fit(x_train, y_train)\n",
    "\n",
    "eval_model(rfc_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With a forest size of 1, the random forest behaves as a standalone decision tree and is unable to distinguish between the two classes\n",
    "- With AUC of 0.52 it is only marginally better than a random classifier\n",
    "\n",
    "Let's see what happens if we increase the number of trees to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = RandomForestClassifier(n_estimators=10)\n",
    "rfc_model.fit(x_train, y_train)\n",
    "\n",
    "eval_model(rfc_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We see here that with a forest size of 10 the separation ability of the model increases with an AUC of 0.58\n",
    "- Multiple peaks on the distribution chart suggest that this is not a very stable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = RandomForestClassifier(n_estimators=100)\n",
    "rfc_model.fit(x_train, y_train)\n",
    "\n",
    "eval_model(rfc_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With 100 estimators the AUC improved from 0.58 to 0.62\n",
    "- Class distributions appeared more defined and settled\n",
    "\n",
    "What about if we increase to 300?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = RandomForestClassifier(n_estimators=300)\n",
    "rfc_model.fit(x_train, y_train)\n",
    "\n",
    "eval_model(rfc_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very similar performance to the default value of 100! \n",
    "\n",
    "Increasing the size of the forest helps classification performance up to a point\n",
    "\n",
    "However, it also increases the computational cost of training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "rfc_model.fit(x_train, y_train)\n",
    "\n",
    "eval_model(rfc_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have increased the AUC but the model is failing to identify any loan defaults\n",
    "\n",
    "Let's take a look at how it performs on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(rfc_model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the test data, the model is not identifying any defaults.\n",
    "\n",
    "Very similar performance between training and test data tells us we are not overfitting anymore, but the model has very little predictive power\n",
    "\n",
    "Limiting the tree size to 5 has probably oversimplified the model and actually given us an underfit model!\n",
    "\n",
    "Let's try again with a larger max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "rfc_model.fit(x_train, y_train)\n",
    "\n",
    "eval_model(rfc_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note here! \n",
    "\n",
    "We have increased the AUC to ~0.65, this model has the best ability to separate classes that we have seen so far! \n",
    "\n",
    "It is also has a very good precision score of 67%, but we are still identifying very few loan defaults hence the poor recall\n",
    "\n",
    "Let's have a look at the training set performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(rfc_model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model does perform better on the training data so it could be a little overfitted. However, it certainly is much less dramatic than before! \n",
    "\n",
    "We have now limited the complexity of the trees in our forest which has reduced overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
